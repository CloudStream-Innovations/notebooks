# Data Preparation for ETL Process

This repository contains Jupyter Notebook files for preparing datasets for the Extract, Transform, Load (ETL) process using Python. The notebooks guide users through various data preparation steps, including file extraction, manipulation, and formatting, to ensure the datasets are well-prepared for subsequent data processing tasks.

## Notebooks

### 1. data_preparation.ipynb

- This notebook outlines the initial steps to prepare a dataset for the ETL process.
- It covers tasks such as file extraction, data manipulation, and formatting using Python functions.

### 2. additional_data_preparation.ipynb

- This notebook provides additional data preparation steps beyond the basics covered in the first notebook.
- It includes more advanced data cleaning, transformation, and validation techniques to further refine the dataset.

## Usage

1. Clone the repository to your local machine:
   
   ```
   gh repo clone CloudStream-Innovations/notebooks
   ```

2. Navigate to the repository directory:
   ```
   cd notebooks
   ```

3. Open the Jupyter Notebook files using Jupyter Notebook or JupyterLab:
   ```
   jupyter notebook
   ```
   or
   ```
   jupyter lab
   ```

4. Follow the instructions in the notebooks to prepare your datasets for the ETL process.

## Requirements

- Python 3.x
- Jupyter Notebook
- Required Python libraries (specified in the notebooks)

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgements

- Thank you to the contributors and maintainers of the Python libraries used in this project.
